{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "import imutils\n",
    "from scipy.spatial import distance as dist\n",
    "import streamlit as st\n",
    "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve, plot_precision_recall_curve\n",
    "from sklearn.metrics import precision_score, recall_score \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING WEIGHTS FOR SOCIAL DISTANCING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_person=[]\n",
    "number_of_people_violationg_socialdistancing=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"yolo-coco/yolov3.weights\"\n",
    "cfg = \"yolo-coco/yolov3.cfg\"\n",
    "label_path= \"yolo-coco/coco.names\"\n",
    "net = cv2.dnn.readNetFromDarknet(cfg,model)\n",
    "labels= open(label_path).read().strip().split(\"\\n\")\n",
    "ln= net.getLayerNames()\n",
    "ln = ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ENTERING THE PARAMETER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_threshold=0.3\n",
    "minimum_probability =0.3\n",
    "minimum_distance = 50 \n",
    "display = 1\n",
    "output=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TAKING THE INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnet.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\\nnet.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_location = \"pedestrians.mp4\"\n",
    "\"\"\"\n",
    "net.setPreferableBackend(cv2.dnn.DNN_BACKEND_CUDA)\n",
    "net.setPreferableTarget(cv2.dnn.DNN_TARGET_CUDA)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTIONS TO IMPLEMENT WHETHER ITS A PEROSN OR NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_people(frame, net, ln, personIdx=0):\n",
    "    # grab the dimensions of the frame and  initialize the list of\n",
    "    # results\n",
    "    (H, W) = frame.shape[:2]\n",
    "    results = []\n",
    "\n",
    "    # construct a blob from the input frame and then perform a forward\n",
    "    # pass of the YOLO object detector, giving us our bounding boxes\n",
    "    # and associated probabilities\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416),\n",
    "        swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layerOutputs = net.forward(ln)\n",
    "\n",
    "    # initialize our lists of detected bounding boxes, centroids, and\n",
    "    # confidences, respectively\n",
    "    boxes = []\n",
    "    centroids = []\n",
    "    confidences = []\n",
    "\n",
    "    # loop over each of the layer outputs\n",
    "    for output in layerOutputs:\n",
    "        # loop over each of the detections\n",
    "        for detection in output:\n",
    "            # extract the class ID and confidence (i.e., probability)\n",
    "            # of the current object detection\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "\n",
    "            # filter detections by (1) ensuring that the object\n",
    "            # detected was a person and (2) that the minimum\n",
    "            # confidence is met\n",
    "            if classID == personIdx and confidence > 0.3:\n",
    "                \n",
    "                # scale the bounding box coordinates back relative to\n",
    "                # the size of the image, keeping in mind that YOLO\n",
    "                # actually returns the center (x, y)-coordinates of\n",
    "                # the bounding box followed by the boxes' width and\n",
    "                # height\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                # use the center (x, y)-coordinates to derive the top\n",
    "                # and and left corner of the bounding box\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "\n",
    "                # update our list of bounding box coordinates,\n",
    "                # centroids, and confidences\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                centroids.append((centerX, centerY))\n",
    "                confidences.append(float(confidence))\n",
    "\n",
    "    # apply non-maxima suppression to suppress weak, overlapping\n",
    "    # bounding boxes\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.3, 0.3)\n",
    "\n",
    "    # ensure at least one detection exists\n",
    "    if len(idxs) > 0:\n",
    "        # loop over the indexes we are keeping\n",
    "        for i in idxs.flatten():\n",
    "            # extract the bounding box coordinates\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "\n",
    "            # update our results list to consist of the person\n",
    "            # prediction probability, bounding box coordinates,\n",
    "            # and the centroid\n",
    "            r = (confidences[i], (x, y, x + w, y + h), centroids[i])\n",
    "            results.append(r)\n",
    "\n",
    "    # return the list of results\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INITIALIZING THE VIDEO STREAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs=cv2.VideoCapture(input_location if input_location else 0)\n",
    "writer =None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwhile True:\\n    (grabbed,frame)=vs.read()\\n    frame = imutils.resize(frame,width=700)\\n    results =detect_person(frame, net, ln,minimum_threshold,minimum_probability,personIdx=labels.index(\"person\"))\\n    violate = set()\\n    if len(results)>=2:\\n        centroids = np.array([r[2] for r in results])\\n        D = dist.cdist(centroids,centroids,metric=\"euclidean\")\\n        for i in range(0,D.shape[0]):\\n            for j in range(i+1,D.shape[1]):\\n                if D[i,j]<minimum_distance:\\n                    violate.add(i)\\n                    violate.add(j)\\n    for (i,(prob,bbox,centroid)) in enumerate(results):\\n        (startX,startY,endX,endY)=bbox\\n        (cx,cy)=centroid\\n        color =(0,255,0)\\n        color_centre=(255,0,0)\\n        if i in violate:\\n            color =(0,0,255)\\n        cv2.rectangle(frame,(startX,startY),(endX,endY),color,2)\\n        cv2.circle(frame,(cx,cy),5,color_centre,1)\\n    text = \"Social Distancing Violations: {}\".format(len(violate))\\n    cv2.putText(frame, text, (10, frame.shape[0] - 25),cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 255), 3)\\n    if display>0:\\n        cv2_imshow(frame)\\n        key = cv2.waitKey(1) & 0xFF\\n        if key==ord(\"q\"):\\n            break\\n    if output!= \"\" and writer is None:\\n        # initialize our video writer\\n        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\\n        writer = cv2.VideoWriter(args[\"output\"], fourcc, 25,\\n            (frame.shape[1], frame.shape[0]), True)\\n    # if the video writer is not None, write the frame to the output\\n    # video file\\n    if writer is not None:\\n        writer.write(frame)\\n        '"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while True:\n",
    "    # read the next frame from the file\n",
    "    (grabbed, frame) = vs.read()\n",
    "\n",
    "    # if the frame was not grabbed, then we have reached the end\n",
    "    # of the stream\n",
    "    if not grabbed:\n",
    "        break\n",
    "\n",
    "    # resize the frame and then detect people (and only people) in it\n",
    "    frame = imutils.resize(frame, width=700)\n",
    "    results= detect_people(frame, net, ln,\n",
    "        personIdx=labels.index(\"person\"))\n",
    "\n",
    "    # initialize the set of indexes that violate the minimum social\n",
    "    # distance\n",
    "    violate = set()\n",
    "    \n",
    "\n",
    "    # ensure there are *at least* two people detections (required in\n",
    "    # order to compute our pairwise distance maps)\n",
    "    if len(results) >= 2:\n",
    "        # extract all centroids from the results and compute the\n",
    "        # Euclidean distances between all pairs of the centroids\n",
    "        centroids = np.array([r[2] for r in results])\n",
    "        D = dist.cdist(centroids, centroids, metric=\"euclidean\")\n",
    "\n",
    "        # loop over the upper triangular of the distance matrix\n",
    "        for i in range(0, D.shape[0]):\n",
    "            for j in range(i + 1, D.shape[1]):\n",
    "                # check to see if the distance between any two\n",
    "                # centroid pairs is less than the configured number\n",
    "                # of pixels\n",
    "                if D[i, j] < minimum_distance  :\n",
    "                    #number_of_people_violationg_socialdistancing=number_of_people_violationg_socialdistancing+1\n",
    "                    # update our violation set with the indexes of\n",
    "                    # the centroid pairs\n",
    "                    violate.add(i)\n",
    "                    violate.add(j)\n",
    "    \n",
    "    # loop over the results\n",
    "    for (i, (prob, bbox, centroid)) in enumerate(results):\n",
    "        # extract the bounding box and centroid coordinates, then\n",
    "        # initialize the color of the annotation\n",
    "        (startX, startY, endX, endY) = bbox\n",
    "        (cX, cY) = centroid\n",
    "        color = (0, 255, 0)\n",
    "\n",
    "        # if the index pair exists within the violation set, then\n",
    "        # update the color\n",
    "        if i in violate:\n",
    "            color = (0, 0, 255)\n",
    "        number_of_people_violationg_socialdistancing.append(len(violate))\n",
    "        total_person.append(len(results))\n",
    "\n",
    "        # draw (1) a bounding box around the person and (2) the\n",
    "        # centroid coordinates of the person,\n",
    "        cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "        cv2.circle(frame, (cX, cY), 5, color, 1)\n",
    "\n",
    "    # draw the total number of social distancing violations on the\n",
    "    # output frame\n",
    "    text = \"Social Distancing Violations: {}\".format(len(violate))\n",
    "    cv2.putText(frame, text, (10, frame.shape[0] - 25),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 255), 3)\n",
    "\n",
    "    # check to see if the output frame should be displayed to our\n",
    "    # screen\n",
    "    if display> 0:\n",
    "        # show the output frame\n",
    "        cv2.imshow(\"Frame\",frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        # if the `q` key was pressed, break from the loop\n",
    "        if key == ord(\"q\"):\n",
    "            #number_of_people_violationg_socialdistancing=len(violate)\n",
    "            break\n",
    "\n",
    "    # if an output video file path has been supplied and the video\n",
    "    # writer has not been initialized, do so now\n",
    "    if output != \"\" and writer is None:\n",
    "        # initialize our video writer\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "        writer = cv2.VideoWriter(args[\"output\"], fourcc, 25000000,\n",
    "            (frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "    # if the video writer is not None, write the frame to the output\n",
    "    # video file\n",
    "    if writer is not None:\n",
    "        writer.write(frame)\n",
    "\"\"\"\n",
    "while True:\n",
    "    (grabbed,frame)=vs.read()\n",
    "    frame = imutils.resize(frame,width=700)\n",
    "    results =detect_person(frame, net, ln,minimum_threshold,minimum_probability,personIdx=labels.index(\"person\"))\n",
    "    violate = set()\n",
    "    if len(results)>=2:\n",
    "        centroids = np.array([r[2] for r in results])\n",
    "        D = dist.cdist(centroids,centroids,metric=\"euclidean\")\n",
    "        for i in range(0,D.shape[0]):\n",
    "            for j in range(i+1,D.shape[1]):\n",
    "                if D[i,j]<minimum_distance:\n",
    "                    violate.add(i)\n",
    "                    violate.add(j)\n",
    "    for (i,(prob,bbox,centroid)) in enumerate(results):\n",
    "        (startX,startY,endX,endY)=bbox\n",
    "        (cx,cy)=centroid\n",
    "        color =(0,255,0)\n",
    "        color_centre=(255,0,0)\n",
    "        if i in violate:\n",
    "            color =(0,0,255)\n",
    "        cv2.rectangle(frame,(startX,startY),(endX,endY),color,2)\n",
    "        cv2.circle(frame,(cx,cy),5,color_centre,1)\n",
    "    text = \"Social Distancing Violations: {}\".format(len(violate))\n",
    "    cv2.putText(frame, text, (10, frame.shape[0] - 25),cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 255), 3)\n",
    "    if display>0:\n",
    "        cv2_imshow(frame)\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key==ord(\"q\"):\n",
    "            break\n",
    "    if output!= \"\" and writer is None:\n",
    "        # initialize our video writer\n",
    "        fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "        writer = cv2.VideoWriter(args[\"output\"], fourcc, 25,\n",
    "            (frame.shape[1], frame.shape[0]), True)\n",
    "    # if the video writer is not None, write the frame to the output\n",
    "    # video file\n",
    "    if writer is not None:\n",
    "        writer.write(frame)\n",
    "        \"\"\"\n",
    "        \n",
    "            \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687\n"
     ]
    }
   ],
   "source": [
    "print(len(number_of_people_violationg_socialdistancing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "687\n"
     ]
    }
   ],
   "source": [
    "print(len(total_person))\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No handles with labels found to put in legend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20356276988>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sns.set_style(\"darkgrid\")\n",
    "x=total_person\n",
    "plt.plot(x)\n",
    "y=number_of_people_violationg_socialdistancing\n",
    "plt.plot(y)\n",
    "plt.xlabel('Number of Frames')\n",
    "plt.ylabel('Number of People')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ml_server.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ml_server.py\n",
    "import json\n",
    "import numpy as np\n",
    "import random \n",
    "from flask import Flask,request\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "import imutils\n",
    "from scipy.spatial import distance as dist\n",
    "import streamlit as st\n",
    "from sklearn.metrics import plot_confusion_matrix, plot_roc_curve, plot_precision_recall_curve\n",
    "from sklearn.metrics import precision_score, recall_score \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "app = Flask(__name__)\n",
    "model = \"yolo-coco/yolov3.weights\"\n",
    "cfg = \"yolo-coco/yolov3.cfg\"\n",
    "label_path= \"yolo-coco/coco.names\"\n",
    "net = cv2.dnn.readNetFromDarknet(cfg,model)\n",
    "labels= open(label_path).read().strip().split(\"\\n\")\n",
    "ln= net.getLayerNames()\n",
    "ln = ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "net = cv2.dnn.readNetFromDarknet(cfg,model)\n",
    "\n",
    "minimum_threshold=0.3\n",
    "minimum_probability =0.3\n",
    "minimum_distance = 50 \n",
    "display = 1\n",
    "output=\"\"\n",
    "\n",
    "input_location = \"pedestrians.mp4\"\n",
    "\n",
    "def detect_people(frame, net, ln, personIdx=0):\n",
    "    # grab the dimensions of the frame and  initialize the list of\n",
    "    # results\n",
    "    (H, W) = frame.shape[:2]\n",
    "    results = []\n",
    "\n",
    "    # construct a blob from the input frame and then perform a forward\n",
    "    # pass of the YOLO object detector, giving us our bounding boxes\n",
    "    # and associated probabilities\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416),\n",
    "        swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layerOutputs = net.forward(ln)\n",
    "\n",
    "    # initialize our lists of detected bounding boxes, centroids, and\n",
    "    # confidences, respectively\n",
    "    boxes = []\n",
    "    centroids = []\n",
    "    confidences = []\n",
    "\n",
    "    # loop over each of the layer outputs\n",
    "    for output in layerOutputs:\n",
    "        # loop over each of the detections\n",
    "        for detection in output:\n",
    "            # extract the class ID and confidence (i.e., probability)\n",
    "            # of the current object detection\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "\n",
    "            # filter detections by (1) ensuring that the object\n",
    "            # detected was a person and (2) that the minimum\n",
    "            # confidence is met\n",
    "            if classID == personIdx and confidence > 0.3:\n",
    "                \n",
    "                # scale the bounding box coordinates back relative to\n",
    "                # the size of the image, keeping in mind that YOLO\n",
    "                # actually returns the center (x, y)-coordinates of\n",
    "                # the bounding box followed by the boxes' width and\n",
    "                # height\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                # use the center (x, y)-coordinates to derive the top\n",
    "                # and and left corner of the bounding box\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "\n",
    "                # update our list of bounding box coordinates,\n",
    "                # centroids, and confidences\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                centroids.append((centerX, centerY))\n",
    "                confidences.append(float(confidence))\n",
    "\n",
    "    # apply non-maxima suppression to suppress weak, overlapping\n",
    "    # bounding boxes\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.3, 0.3)\n",
    "\n",
    "    # ensure at least one detection exists\n",
    "    if len(idxs) > 0:\n",
    "        # loop over the indexes we are keeping\n",
    "        for i in idxs.flatten():\n",
    "            # extract the bounding box coordinates\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "\n",
    "            # update our results list to consist of the person\n",
    "            # prediction probability, bounding box coordinates,\n",
    "            # and the centroid\n",
    "            r = (confidences[i], (x, y, x + w, y + h), centroids[i])\n",
    "            results.append(r)\n",
    "\n",
    "    # return the list of results\n",
    "    return results\n",
    "\n",
    "def final_pred():\n",
    "    while True:\n",
    "        # read the next frame from the file\n",
    "        (grabbed, frame) = vs.read()\n",
    "\n",
    "        # if the frame was not grabbed, then we have reached the end\n",
    "        # of the stream\n",
    "        if not grabbed:\n",
    "            break\n",
    "\n",
    "        # resize the frame and then detect people (and only people) in it\n",
    "        frame = imutils.resize(frame, width=700)\n",
    "        results= detect_people(frame, net, ln,\n",
    "            personIdx=labels.index(\"person\"))\n",
    "\n",
    "        # initialize the set of indexes that violate the minimum social\n",
    "        # distance\n",
    "        violate = set()\n",
    "\n",
    "\n",
    "        # ensure there are *at least* two people detections (required in\n",
    "        # order to compute our pairwise distance maps)\n",
    "        if len(results) >= 2:\n",
    "            # extract all centroids from the results and compute the\n",
    "            # Euclidean distances between all pairs of the centroids\n",
    "            centroids = np.array([r[2] for r in results])\n",
    "            D = dist.cdist(centroids, centroids, metric=\"euclidean\")\n",
    "\n",
    "            # loop over the upper triangular of the distance matrix\n",
    "            for i in range(0, D.shape[0]):\n",
    "                for j in range(i + 1, D.shape[1]):\n",
    "                    # check to see if the distance between any two\n",
    "                    # centroid pairs is less than the configured number\n",
    "                    # of pixels\n",
    "                    if D[i, j] < minimum_distance  :\n",
    "                        #number_of_people_violationg_socialdistancing=number_of_people_violationg_socialdistancing+1\n",
    "                        # update our violation set with the indexes of\n",
    "                        # the centroid pairs\n",
    "                        violate.add(i)\n",
    "                        violate.add(j)\n",
    "\n",
    "        # loop over the results\n",
    "        for (i, (prob, bbox, centroid)) in enumerate(results):\n",
    "            # extract the bounding box and centroid coordinates, then\n",
    "            # initialize the color of the annotation\n",
    "            (startX, startY, endX, endY) = bbox\n",
    "            (cX, cY) = centroid\n",
    "            color = (0, 255, 0)\n",
    "\n",
    "            # if the index pair exists within the violation set, then\n",
    "            # update the color\n",
    "            if i in violate:\n",
    "                color = (0, 0, 255)\n",
    "            number_of_people_violationg_socialdistancing.append(len(violate))\n",
    "            total_person.append(len(results))\n",
    "\n",
    "            # draw (1) a bounding box around the person and (2) the\n",
    "            # centroid coordinates of the person,\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "            cv2.circle(frame, (cX, cY), 5, color, 1)\n",
    "\n",
    "        # draw the total number of social distancing violations on the\n",
    "        # output frame\n",
    "        text = \"Social Distancing Violations: {}\".format(len(violate))\n",
    "        cv2.putText(frame, text, (10, frame.shape[0] - 25),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 255), 3)\n",
    "\n",
    "        # check to see if the output frame should be displayed to our\n",
    "        # screen\n",
    "        if display> 0:\n",
    "            # show the output frame\n",
    "            cv2.imshow(\"Frame\",frame)\n",
    "            key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "            # if the `q` key was pressed, break from the loop\n",
    "            if key == ord(\"q\"):\n",
    "                #number_of_people_violationg_socialdistancing=len(violate)\n",
    "                break\n",
    "\n",
    "        # if an output video file path has been supplied and the video\n",
    "        # writer has not been initialized, do so now\n",
    "        if output != \"\" and writer is None:\n",
    "            # initialize our video writer\n",
    "            fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "            writer = cv2.VideoWriter(args[\"output\"], fourcc, 25000000,\n",
    "                (frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "        # if the video writer is not None, write the frame to the output\n",
    "        # video file\n",
    "        if writer is not None:\n",
    "            writer.write(frame)\n",
    "\n",
    "        return total_person, number_of_people_violationg_socialdistancing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/',methods=['GET','POST'])\n",
    "def index():\n",
    "    if request.method=='POST':\n",
    "        total_person,number_of_people_violationg_socialdistancing= final_pred()\n",
    "        return json.dumps({'TOTAL PERSON': total_person,'SOCIAL DISTANCE VIOLATIONS':number_of_people_violationg_socialdistancing})\n",
    "    return 'Welcome'\n",
    "if __name__=='__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app.py\n",
    "import cv2\n",
    "import streamlit as st\n",
    "import json\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import imutils\n",
    "from scipy.spatial import distance as dist\n",
    "def main():\n",
    "    st.title(\"Social Distancing Anlyzer Web App\")\n",
    "    st.sidebar.title(\"Social Distancing Anlyzer Web App\")\n",
    "    st.markdown(\"Find total numberr of peoples who are following social-distancing \")\n",
    "    st.sidebar.markdown(\"Find total numberr of peoples who are following social-distancing  \")\n",
    "    filename = open('pedestrians.mp4','rb')\n",
    "    video_bites = filename.read()\n",
    "    st.sidebar.text(\"Input Video:\")\n",
    "    st.sidebar.video(video_bites)\n",
    "    \n",
    "    app_mode = st.sidebar.selectbox(\"Choose the app mode\",\n",
    "        [\"About the App\", \"Run the app\", \"Show the source code\"])\n",
    "    if app_mode == \"About the App\":\n",
    "        st.text('This is an app which detects whether the person is following social-distancing or not ')\n",
    "        st.text('over an area with the help of CCTV footage or any video source and plots the data of same ')\n",
    "    elif app_mode == \"Show the source code\":\n",
    "        with st.echo():\n",
    "            Link = \"https://github.com/shreyanshsatvik/covid_tracer\"\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    elif app_mode == \"Run the app\":\n",
    "        model = \"yolo-coco/yolov3.weights\"\n",
    "        cfg = \"yolo-coco/yolov3.cfg\"\n",
    "        label_path= \"yolo-coco/coco.names\"\n",
    "        input_location = \"pedestrians.mp4\"\n",
    "        net = cv2.dnn.readNetFromDarknet(cfg,model)\n",
    "        labels= open(label_path).read().strip().split(\"\\n\")\n",
    "        ln= net.getLayerNames()\n",
    "        ln = ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "        minimum_threshold=0.3\n",
    "        minimum_probability =0.3\n",
    "        minimum_distance = 50 \n",
    "        display = 1\n",
    "        output=\"\"\n",
    "        total_person=[]\n",
    "        number_of_people_violationg_socialdistancing=[]\n",
    "        \n",
    "        def detect_people(frame, net, ln, personIdx=0):\n",
    "            # grab the dimensions of the frame and  initialize the list of\n",
    "            # results\n",
    "            (H, W) = frame.shape[:2]\n",
    "            results = []\n",
    "\n",
    "            # construct a blob from the input frame and then perform a forward\n",
    "            # pass of the YOLO object detector, giving us our bounding boxes\n",
    "            # and associated probabilities\n",
    "            blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416),\n",
    "                swapRB=True, crop=False)\n",
    "            net.setInput(blob)\n",
    "            layerOutputs = net.forward(ln)\n",
    "\n",
    "            # initialize our lists of detected bounding boxes, centroids, and\n",
    "            # confidences, respectively\n",
    "            boxes = []\n",
    "            centroids = []\n",
    "            confidences = []\n",
    "\n",
    "            # loop over each of the layer outputs\n",
    "            for output in layerOutputs:\n",
    "                # loop over each of the detections\n",
    "                for detection in output:\n",
    "                    # extract the class ID and confidence (i.e., probability)\n",
    "                    # of the current object detection\n",
    "                    scores = detection[5:]\n",
    "                    classID = np.argmax(scores)\n",
    "                    confidence = scores[classID]\n",
    "\n",
    "                    # filter detections by (1) ensuring that the object\n",
    "                    # detected was a person and (2) that the minimum\n",
    "                    # confidence is met\n",
    "                    if classID == personIdx and confidence > 0.3:\n",
    "\n",
    "                        # scale the bounding box coordinates back relative to\n",
    "                        # the size of the image, keeping in mind that YOLO\n",
    "                        # actually returns the center (x, y)-coordinates of\n",
    "                        # the bounding box followed by the boxes' width and\n",
    "                        # height\n",
    "                        box = detection[0:4] * np.array([W, H, W, H])\n",
    "                        (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                        # use the center (x, y)-coordinates to derive the top\n",
    "                        # and and left corner of the bounding box\n",
    "                        x = int(centerX - (width / 2))\n",
    "                        y = int(centerY - (height / 2))\n",
    "\n",
    "                        # update our list of bounding box coordinates,\n",
    "                        # centroids, and confidences\n",
    "                        boxes.append([x, y, int(width), int(height)])\n",
    "                        centroids.append((centerX, centerY))\n",
    "                        confidences.append(float(confidence))\n",
    "\n",
    "            # apply non-maxima suppression to suppress weak, overlapping\n",
    "            # bounding boxes\n",
    "            idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.3, 0.3)\n",
    "\n",
    "            # ensure at least one detection exists\n",
    "            if len(idxs) > 0:\n",
    "                # loop over the indexes we are keeping\n",
    "                for i in idxs.flatten():\n",
    "                    # extract the bounding box coordinates\n",
    "                    (x, y) = (boxes[i][0], boxes[i][1])\n",
    "                    (w, h) = (boxes[i][2], boxes[i][3])\n",
    "\n",
    "                    # update our results list to consist of the person\n",
    "                    # prediction probability, bounding box coordinates,\n",
    "                    # and the centroid\n",
    "                    r = (confidences[i], (x, y, x + w, y + h), centroids[i])\n",
    "                    results.append(r)\n",
    "\n",
    "            # return the list of results\n",
    "            return results\n",
    "        if st.button('Show Results in the video'):\n",
    "            \n",
    "            vs=cv2.VideoCapture(input_location if input_location else 0)\n",
    "            writer =None\n",
    "            while True:\n",
    "\n",
    "                # read the next frame from the file\n",
    "                (grabbed, frame) = vs.read()\n",
    "\n",
    "                # if the frame was not grabbed, then we have reached the end\n",
    "                # of the stream\n",
    "                if not grabbed:\n",
    "                    break\n",
    "\n",
    "                # resize the frame and then detect people (and only people) in it\n",
    "                frame = imutils.resize(frame, width=700)\n",
    "                results= detect_people(frame, net, ln,\n",
    "                    personIdx=labels.index(\"person\"))\n",
    "\n",
    "                # initialize the set of indexes that violate the minimum social\n",
    "                # distance\n",
    "                violate = set()\n",
    "\n",
    "\n",
    "                # ensure there are *at least* two people detections (required in\n",
    "                # order to compute our pairwise distance maps)\n",
    "                if len(results) >= 2:\n",
    "                    # extract all centroids from the results and compute the\n",
    "                    # Euclidean distances between all pairs of the centroids\n",
    "                    centroids = np.array([r[2] for r in results])\n",
    "                    D = dist.cdist(centroids, centroids, metric=\"euclidean\")\n",
    "\n",
    "                    # loop over the upper triangular of the distance matrix\n",
    "                    for i in range(0, D.shape[0]):\n",
    "                        for j in range(i + 1, D.shape[1]):\n",
    "                            # check to see if the distance between any two\n",
    "                            # centroid pairs is less than the configured number\n",
    "                            # of pixels\n",
    "                            if D[i, j] < minimum_distance  :\n",
    "                                #number_of_people_violationg_socialdistancing=number_of_people_violationg_socialdistancing+1\n",
    "                                # update our violation set with the indexes of\n",
    "                                # the centroid pairs\n",
    "                                violate.add(i)\n",
    "                                violate.add(j)\n",
    "\n",
    "                # loop over the results\n",
    "                for (i, (prob, bbox, centroid)) in enumerate(results):\n",
    "                    # extract the bounding box and centroid coordinates, then\n",
    "                    # initialize the color of the annotation\n",
    "                    (startX, startY, endX, endY) = bbox\n",
    "                    (cX, cY) = centroid\n",
    "                    color = (0, 255, 0)\n",
    "\n",
    "                    # if the index pair exists within the violation set, then\n",
    "                    # update the color\n",
    "                    if i in violate:\n",
    "                        color = (0, 0, 255)\n",
    "                    number_of_people_violationg_socialdistancing.append(len(violate))\n",
    "                    total_person.append(len(results))\n",
    "\n",
    "                    # draw (1) a bounding box around the person and (2) the\n",
    "                    # centroid coordinates of the person,\n",
    "                    cv2.rectangle(frame, (startX, startY), (endX, endY), color, 2)\n",
    "                    cv2.circle(frame, (cX, cY), 5, color, 1)\n",
    "\n",
    "                # draw the total number of social distancing violations on the\n",
    "                # output frame\n",
    "                text = \"Social Distancing Violations: {}\".format(len(violate))\n",
    "                cv2.putText(frame, text, (10, frame.shape[0] - 25),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.85, (0, 0, 255), 3)\n",
    "\n",
    "                # check to see if the output frame should be displayed to our\n",
    "                # screen\n",
    "                if display> 0:\n",
    "                    # show the output frame\n",
    "                    cv2.imshow(\"Frame\",frame)\n",
    "                    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "                    # if the `q` key was pressed, break from the loop\n",
    "                    if key == ord(\"q\"):\n",
    "                        filename1 = open('output.mp4','rb')\n",
    "                        video_bites1 = filename1.read()\n",
    "                        st.text(\"Output Video:\")\n",
    "                        st.video(video_bites1)\n",
    "                        #number_of_people_violationg_socialdistancing=len(violate)\n",
    "                        break\n",
    "                        \n",
    "\n",
    "                # if an output video file path has been supplied and the video\n",
    "                # writer has not been initialized, do so now\n",
    "                if output != \"\" and writer is None:\n",
    "                    # initialize our video writer\n",
    "                    fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "                    writer = cv2.VideoWriter(args[\"output\"], fourcc, 25000000,\n",
    "                        (frame.shape[1], frame.shape[0]), True)\n",
    "\n",
    "                # if the video writer is not None, write the frame to the output\n",
    "                # video file\n",
    "                if writer is not None:\n",
    "                    writer.write(frame)\n",
    "                    \n",
    "            \n",
    "            \n",
    "            plt.plot(total_person)\n",
    "            plt.plot(number_of_people_violationg_socialdistancing)\n",
    "            plt.xlabel('Number of Frames')\n",
    "            plt.ylabel('Number of People')\n",
    "            st.pyplot()\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model():\n",
    "    abra=5\n",
    "    dabra=10\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dabra' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-112-c87fbad0fd8e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdabra\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dabra' is not defined"
     ]
    }
   ],
   "source": [
    "dabra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "URI = ' http://127.0.0.1:5000/'\n",
    "\n",
    "\n",
    "st.title(\"Social Distancing Anlyzer Web App\")\n",
    "st.sidebar.title(\"Social Distancing Anlyzer Web App\")\n",
    "st.markdown(\"Find total numberr of peoples who are following social-distancing \")\n",
    "st.sidebar.markdown(\"Find total numberr of peoples who are following social-distancing  \")\n",
    "filename = open('pedestrians.mp4','rb')\n",
    "video_bites = filename.read()\n",
    "st.sidebar.text(\"Input Video:\")\n",
    "st.sidebar.video(video_bites)\n",
    "if st.button('Get Predictions'):\n",
    "    response = requests.post(URI,data={})\n",
    "    response = json.loads(response.text)\n",
    "    Total_Person =respone.get('TOTAL PERSON')\n",
    "    Violations = response.get('SOCIAL DISTANCE VIOLATIONS')\n",
    "    \n",
    "    st.dataframe(Total_person)\n",
    "    \n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
